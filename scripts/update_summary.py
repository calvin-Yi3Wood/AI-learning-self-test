#!/usr/bin/env python3
"""
æ›´æ–°æ±‡æ€»ç»Ÿè®¡
æ¯æ¬¡æœ‰æ–°æ•°æ®æäº¤æ—¶è‡ªåŠ¨è¿è¡Œ
"""

import json
import os
from datetime import datetime
from pathlib import Path
from collections import Counter, defaultdict

def load_all_test_data():
    """åŠ è½½æ‰€æœ‰æµ‹è¯•æ•°æ®"""
    data_dir = Path('data/raw')
    all_data = []

    if not data_dir.exists():
        return all_data

    for json_file in data_dir.glob('test_*.json'):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                all_data.append(data)
        except Exception as e:
            print(f"âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥ {json_file}: {e}")

    return all_data

def calculate_statistics(all_data):
    """è®¡ç®—ç»Ÿè®¡æ•°æ®"""
    if not all_data:
        return {
            'total_tests': 0,
            'last_updated': datetime.now().isoformat()
        }

    # åŸºç¡€ç»Ÿè®¡
    stats = {
        'total_tests': len(all_data),
        'last_updated': datetime.now().isoformat(),
        'first_test_date': min(d['timestamp'] for d in all_data),
        'last_test_date': max(d['timestamp'] for d in all_data)
    }

    # è·¯çº¿åˆ†å¸ƒç»Ÿè®¡
    main_routes = [d['result']['mainRoute'] for d in all_data if 'result' in d]
    stats['route_distribution'] = dict(Counter(main_routes))

    # ç»´åº¦å¾—åˆ†ç»Ÿè®¡
    dimension_scores = defaultdict(list)
    for data in all_data:
        if 'dimensionScores' in data:
            for dim, score in data['dimensionScores'].items():
                dimension_scores[dim].append(score)

    stats['dimension_averages'] = {
        dim: round(sum(scores) / len(scores), 2)
        for dim, scores in dimension_scores.items()
    }

    # è®¾å¤‡ç±»å‹ç»Ÿè®¡
    device_types = [d['metadata']['deviceType'] for d in all_data if 'metadata' in d]
    stats['device_distribution'] = dict(Counter(device_types))

    # æ¯æ—¥ç»Ÿè®¡
    daily_counts = defaultdict(int)
    for data in all_data:
        date_str = data['timestamp'][:10]  # æå–æ—¥æœŸéƒ¨åˆ† YYYY-MM-DD
        daily_counts[date_str] += 1

    stats['daily_counts'] = dict(sorted(daily_counts.items()))

    # å®Œæˆç‡ç»Ÿè®¡ï¼ˆä¼°ç®—ï¼‰
    stats['estimated_completion_rate'] = '95%'  # åŸºäºå®é™…å®Œæˆæµ‹è¯•çš„æ•°æ®

    return stats

def save_summary(stats):
    """ä¿å­˜æ±‡æ€»ç»Ÿè®¡"""
    summary_file = Path('data/summary.json')
    summary_file.parent.mkdir(parents=True, exist_ok=True)

    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)

    print(f'âœ… æ±‡æ€»ç»Ÿè®¡å·²æ›´æ–°: {stats["total_tests"]} æ¡æµ‹è¯•æ•°æ®')

def main():
    """ä¸»å‡½æ•°"""
    print('ğŸ“Š å¼€å§‹æ›´æ–°æ±‡æ€»ç»Ÿè®¡...')

    # åŠ è½½æ‰€æœ‰æ•°æ®
    all_data = load_all_test_data()
    print(f'ğŸ“ å·²åŠ è½½ {len(all_data)} æ¡æ•°æ®')

    # è®¡ç®—ç»Ÿè®¡
    stats = calculate_statistics(all_data)

    # ä¿å­˜ç»“æœ
    save_summary(stats)

    # æ‰“å°å…³é”®æŒ‡æ ‡
    print('\nğŸ“ˆ å…³é”®æŒ‡æ ‡:')
    print(f'  - æ€»æµ‹è¯•æ•°: {stats["total_tests"]}')
    if stats['total_tests'] > 0:
        print(f'  - è·¯çº¿åˆ†å¸ƒ: {stats["route_distribution"]}')
        print(f'  - è®¾å¤‡åˆ†å¸ƒ: {stats["device_distribution"]}')
        print(f'  - æ¯æ—¥å¹³å‡: {len(all_data) / max(len(stats["daily_counts"]), 1):.1f} æ¬¡')

if __name__ == '__main__':
    main()
